{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import permutations\n",
    "import json, os\n",
    "from collections import OrderedDict\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import datetime\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "test_log = 'BPIC17_O_Accepted_20'\n",
    "file_dir = 'C:/Users/bruck/OneDrive/바탕 화면/GA_based_AutoML-main/GA_based_AutoML-main/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if 'BPIC11' in test_log:\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'time:timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['Diagnosis', 'Treatment code', 'Diagnosis code', 'Specialism code',\n",
    "           'Diagnosis Treatment Combination ID', 'Age', \n",
    "           'Producer code', 'Section', 'Specialism code.1',\n",
    "           'group', 'Number of executions','timesincemidnight',\n",
    "           'month', 'weekday', 'hour', 'timesincelastevent', 'timesincecasestart',\n",
    "           'event_nr', 'open_cases']\n",
    "\n",
    "    string_event = ['Diagnosis', 'Treatment code', 'Diagnosis code', 'Specialism code',\n",
    "           'Diagnosis Treatment Combination ID',  \n",
    "           'Producer code', 'Section', 'Specialism code.1',\n",
    "           'group' ]\n",
    "    num_event = [ 'Age','Number of executions','timesincemidnight',\n",
    "           'month', 'weekday', 'hour', 'timesincelastevent', 'timesincecasestart',\n",
    "           'event_nr', 'open_cases']\n",
    "    \n",
    "    \n",
    "elif 'BPIC12' in test_log:\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'Complete Timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['AMOUNT_REQ', 'Resource',\n",
    "           'lifecycle:transition', 'timesincemidnight', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'month', 'weekday', 'hour',\n",
    "           'open_cases']\n",
    "    string_event = ['Resource','lifecycle:transition']\n",
    "    num_event = ['timesincemidnight', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'month', 'weekday', 'hour',\n",
    "           'open_cases']\n",
    "\n",
    "    \n",
    "    \n",
    "elif ('BPIC15_1_f2' in test_log) or ('BPIC15_2_f2' in test_log) :\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'time:timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['Responsible_actor', 'SUMleges',\n",
    "           'Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Gebiedsbescherming', 'Handelen in strijd met regels RO',\n",
    "           'Inrit/Uitweg', 'Kap', 'Milieu (melding)',\n",
    "           'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop', \n",
    "           'monitoringResource', 'question', 'org:resource', \n",
    "           'timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "\n",
    "    string_event = ['question','Responsible_actor',\n",
    "           'Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Gebiedsbescherming', 'Handelen in strijd met regels RO',\n",
    "           'Inrit/Uitweg', 'Kap', 'Milieu (melding)',\n",
    "           'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop','monitoringResource',  'org:resource',]\n",
    "    num_event = [ 'SUMleges','timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "\n",
    "    \n",
    "    \n",
    "elif 'BPIC15_3_f2' in test_log:\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'time:timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['Responsible_actor', 'SUMleges',\n",
    "           'Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Flora en Fauna', 'Gebiedsbescherming',\n",
    "           'Handelen in strijd met regels RO', 'Inrit/Uitweg', 'Kap',\n",
    "           'Milieu (melding)', 'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop', \n",
    "           'monitoringResource', 'question', 'org:resource', \n",
    "           'timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "\n",
    "    string_event = ['question','Responsible_actor',\n",
    "           'Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Flora en Fauna', 'Gebiedsbescherming',\n",
    "           'Handelen in strijd met regels RO', 'Inrit/Uitweg', 'Kap',\n",
    "           'Milieu (melding)', 'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop','monitoringResource',  'org:resource',]\n",
    "    num_event = [ 'SUMleges','timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "    \n",
    "    \n",
    "    \n",
    "elif 'BPIC15_4_f2' in test_log:\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'time:timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['Responsible_actor', 'SUMleges', \n",
    "           'Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Flora en Fauna', 'Gebiedsbescherming',\n",
    "           'Handelen in strijd met regels RO', 'Inrit/Uitweg',  'Kap',\n",
    "           'Milieu (melding)', 'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop', \n",
    "           'monitoringResource', 'question', 'org:resource', \n",
    "           'timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "\n",
    "    string_event = ['question','Responsible_actor','Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Flora en Fauna', 'Gebiedsbescherming',\n",
    "           'Handelen in strijd met regels RO', 'Inrit/Uitweg',  'Kap',\n",
    "           'Milieu (melding)', 'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop','monitoringResource',  'org:resource',]\n",
    "    num_event = [ 'SUMleges','timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "    \n",
    "        \n",
    "elif 'BPIC15_5_f2' in test_log:\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'time:timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['Responsible_actor', 'SUMleges', \n",
    "           'Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Flora en Fauna', 'Gebiedsbescherming',\n",
    "           'Handelen in strijd met regels RO', 'Inrit/Uitweg', 'Integraal', 'Kap',\n",
    "           'Milieu (melding)', 'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop', \n",
    "           'monitoringResource', 'question', 'org:resource', \n",
    "           'timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']\n",
    "\n",
    "    string_event = ['question','Responsible_actor','Aanleg (Uitvoeren werk of werkzaamheid)', 'Bouw',\n",
    "           'Brandveilig gebruik (melding)', 'Brandveilig gebruik (vergunning)',\n",
    "           'Flora en Fauna', 'Gebiedsbescherming',\n",
    "           'Handelen in strijd met regels RO', 'Inrit/Uitweg', 'Integraal', 'Kap',\n",
    "           'Milieu (melding)', 'Milieu (neutraal wijziging)',\n",
    "           'Milieu (omgevingsvergunning beperkte milieutoets)',\n",
    "           'Milieu (vergunning)', 'Monument', 'Reclame', 'Sloop','monitoringResource',  'org:resource',]\n",
    "    num_event = [ 'SUMleges','timesincemidnight', 'month', 'weekday', 'hour', 'timesincelastevent',\n",
    "           'timesincecasestart', 'event_nr', 'open_cases']    \n",
    "    \n",
    "    \n",
    "elif 'BPIC17' in test_log:\n",
    "    print('Input Event Log : ',test_log)\n",
    "    caseid = 'Case ID'\n",
    "    activity = 'Activity'\n",
    "    ts = 'time:timestamp'\n",
    "    label = {'label' : 'regular'}\n",
    "    other_features = ['ApplicationType', 'LoanGoal', 'RequestedAmount', \n",
    "           'org:resource', 'Action', 'EventOrigin',\n",
    "           'lifecycle:transition', 'Accepted', 'Selected', 'FirstWithdrawalAmount',\n",
    "           'MonthlyCost', 'NumberOfTerms', 'OfferedAmount', 'CreditScore',\n",
    "           'timesincelastevent', 'timesincecasestart', 'timesincemidnight',\n",
    "           'event_nr', 'month', 'weekday', 'hour', 'open_cases']\n",
    "    string_event = ['ApplicationType', 'LoanGoal','org:resource', 'Action', 'EventOrigin',\n",
    "           'lifecycle:transition','Accepted', 'Selected']\n",
    "    num_event = ['timesincemidnight', 'timesincelastevent', 'NumberOfTerms', 'CreditScore', 'OfferedAmount', 'FirstWithdrawalAmount', 'RequestedAmount',\n",
    "           'MonthlyCost','timesincecasestart', 'event_nr', 'month', 'weekday', 'hour',\n",
    "           'open_cases']\n",
    "\n",
    "    \n",
    "\n",
    "else:\n",
    "    print('Unaccessible Log')\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "combi = ['bucketing', 'encoding', 'drop_act', 'params']\n",
    "\n",
    "options = {\n",
    "    'bucketing' : (1,40), # a number of partitions\n",
    "    \n",
    "    'encoding' : ['index', 'aggregate'],\n",
    "    \n",
    "    'drop_act' : [2,4,6,8], # a number of activities to drop\n",
    "    \n",
    "    'models' : ['Decision Tree','Random Forest','LightGBM','Xgboost'],\n",
    "\n",
    "    'params' : {'Decision Tree':{'max_depth': (2,20),\n",
    "                           'min_samples_leaf': (5,100),\n",
    "                           'criterion': [\"gini\", \"entropy\"]\n",
    "            }, \n",
    "            'Random Forest':{\"n_estimators\": (10,1000), \n",
    "                           \"max_depth\": (2,20),\n",
    "                           \"max_features\": [\"auto\", \"log2\"], \n",
    "                           \"bootstrap\": [True, False],\n",
    "                           \"criterion\": [\"gini\", \"entropy\"]\n",
    "            },\n",
    "            'LightGBM':{'max_depth': (2,20),\n",
    "                      'num_leaves' : (10,500),\n",
    "                      'min_child_samples' : (2,10)\n",
    "            },\n",
    "            'Xgboost':{\"max_depth\": (2,20),\n",
    "                     \"n_estimators\": (10,1000),\n",
    "                     \"learning_rate\": [0.01, 0.05, 0.1]\n",
    "                     \n",
    "            }\n",
    "            }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def add_label(df):       \n",
    "    Label = []\n",
    "    if 'Activity' in label:\n",
    "        label_col = label['Activity']                \n",
    "        for case, group in df.groupby(caseid):\n",
    "            for i in range(len(group)):\n",
    "                if label_col in group[activity].tolist():\n",
    "                    Label.append(1)\n",
    "                else:\n",
    "                    Label.append(0)\n",
    "        label_df = pd.DataFrame(Label, columns = ['Label'])\n",
    "        df = pd.concat([df, label_df], axis=1)\n",
    "        \n",
    "    elif 'label' in label:\n",
    "        label_col = label['label']                \n",
    "        for case, group in df.groupby(caseid):\n",
    "            for i in range(len(group)):\n",
    "                if label_col in group['label'].tolist():\n",
    "                    Label.append(1)\n",
    "                else:\n",
    "                    Label.append(0)\n",
    "        label_df = pd.DataFrame(Label, columns = ['Label'])\n",
    "        df = pd.concat([df, label_df], axis=1)\n",
    "        \n",
    "        \n",
    "    elif 'column' in label:\n",
    "        label_col = label['column']\n",
    "        df = df.rename(columns={label_col : 'Label'})\n",
    "    return df\n",
    "\n",
    "\n",
    "def drop_activity(df, n):\n",
    "    trace_num = df['Case ID'].nunique() # or df['CaseID']\n",
    "    act = df['Activity'].value_counts()\n",
    "    df = df.iloc[[i for i in range(len(df)) if df.iloc[i]['Activity'] not in act[-n:]]]\n",
    "    return df\n",
    "\n",
    "def whole_bucket(df):\n",
    "    result = []\n",
    "    \n",
    "    for prefix in tqdm(range(2,42)):\n",
    "        bucket=[]\n",
    "        for case, group in df.groupby(caseid):\n",
    "            group = group.sort_values(by='event_nr', ascending = True).reset_index(drop=True)\n",
    "            if len(group) >= prefix:\n",
    "                bucket.append(group.iloc[:prefix,:])\n",
    "        new_df = pd.concat(bucket)\n",
    "        result.append(new_df)\n",
    "    \n",
    "    return result\n",
    "\n",
    "def prefix_bound(m, drop_low=False):\n",
    "    if m == 1:\n",
    "        if drop_low == True:\n",
    "            return [[4,40]]\n",
    "        else:\n",
    "            return [[2,40]]\n",
    "    \n",
    "    if drop_low == True:\n",
    "        if m > 37:\n",
    "            m = 37\n",
    "        prefix_len = 37//m\n",
    "        remain = 37%m\n",
    "        prev = 4\n",
    "        bound=[]\n",
    "        for i in range(m):\n",
    "            if i < remain:\n",
    "                bound.append([prev,prev+prefix_len+1])\n",
    "                prev = prev+prefix_len+1\n",
    "            else:\n",
    "                bound.append([prev,prev+prefix_len])\n",
    "                prev = prev+prefix_len\n",
    "    else:  \n",
    "        prefix_len = 39//m\n",
    "        remain = 39%m\n",
    "        prev = 2\n",
    "        bound=[]\n",
    "        for i in range(m):\n",
    "            if i < remain:\n",
    "                bound.append([prev,prev+prefix_len+1])\n",
    "                prev = prev+prefix_len+1\n",
    "            else:\n",
    "                bound.append([prev,prev+prefix_len])\n",
    "                prev = prev+prefix_len\n",
    "        \n",
    "    return bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(file_dir+'dataset/'+test_log+'.csv', low_memory=False)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#df = df.iloc[:df[df['Case ID']==df['Case ID'].unique()[int(df['Case ID'].nunique()/10)]].index[0]]\n",
    "#df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "df = add_label(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df1 = drop_activity(df, 2)\n",
    "df2 = drop_activity(df, 4)\n",
    "df3 = drop_activity(df, 6)\n",
    "df4 = drop_activity(df, 8)\n",
    "\n",
    "df_list1 = whole_bucket(df1)\n",
    "df_list2 = whole_bucket(df2)\n",
    "df_list3 = whole_bucket(df3)\n",
    "df_list4 = whole_bucket(df4)\n",
    "\n",
    "with open('df_list1.pkl', 'wb') as f1:\n",
    "    pickle.dump(df_list1, f1)\n",
    "    \n",
    "with open('df_list2.pkl', 'wb') as f2:\n",
    "    pickle.dump(df_list2, f2)\n",
    "    \n",
    "with open('df_list3.pkl', 'wb') as f3:\n",
    "    pickle.dump(df_list3, f3)\n",
    "    \n",
    "with open('df_list4.pkl', 'wb') as f4:\n",
    "    pickle.dump(df_list4, f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class Genetic_Algorithm:\n",
    "    def __init__(self, df, options : dict, combi : list , caseid : str, activity : str, ts : str, label : dict, other_features : list, string_event : list, num_event : list, phase):\n",
    "        self.df = df\n",
    "        self.options = options\n",
    "        self.combi = combi\n",
    "        self.caseid = caseid\n",
    "        self.activity = activity \n",
    "        self.ts = ts\n",
    "        self.label = label\n",
    "        self.other_features = other_features\n",
    "        self.string_event = string_event\n",
    "        self.num_event = num_event\n",
    "             \n",
    "    def feature_type(self):\n",
    "        df = self.df\n",
    "        feature_dict = {}\n",
    "        for feature in self.other_features:\n",
    "            for case, group in df.groupby(self.caseid):\n",
    "                if len(group[feature].unique()) != 1:\n",
    "                    feature_dict[feature] = 'event'\n",
    "                    break\n",
    "                else:\n",
    "                    feature_dict[feature] = 'case'\n",
    "        self.feature_types = feature_dict\n",
    "        return feature_dict\n",
    "\n",
    "        \n",
    "                \n",
    "\n",
    "    def rand_choice(self, options, key : str):\n",
    "        if  type(options[key]) == tuple:\n",
    "            return np.random.randint(options[key][0], options[key][1])\n",
    "\n",
    "        elif type(options[key]) == list:\n",
    "            return options[key][np.random.randint(0, len(options[key]))]\n",
    "               \n",
    "        \n",
    "    def initial_populations(self, N : int, rand_state = 2022) -> dict:\n",
    "        initial_pop = []\n",
    "        if 'params' in self.combi:\n",
    "            for model in list(self.options['params'].keys()):\n",
    "                for n in range(N):\n",
    "                    result = {}\n",
    "                    result['bucketing'] = self.rand_choice(self.options, 'bucketing')\n",
    "                    result['encoding'] = self.rand_choice(self.options, 'encoding')\n",
    "                    result['drop_act'] = self.rand_choice(self.options, 'drop_act')\n",
    "                    result['models'] = model\n",
    "                    result[model] = {}\n",
    "                    for hp in list(self.options['params'][model].keys()):                             \n",
    "                        result[model][hp] = self.rand_choice(self.options['params'][model], hp)\n",
    "                    initial_pop.append(result)\n",
    "        else:\n",
    "            for n in range(N):\n",
    "                result = {}\n",
    "                result['bucketing'] = rand_choice(self.options, 'bucketing')\n",
    "                result['encoding'] = rand_choice(self.options, 'encoding')\n",
    "                result['drop_act'] = rand_choice(self.options, 'drop_act')\n",
    "                initial_pop.append(result)                \n",
    "        \n",
    "        self.population = initial_pop\n",
    "        \n",
    "        return initial_pop\n",
    "    \n",
    "    def select_population(self, population, fitness, N) -> list:\n",
    "#         population = self.population\n",
    "        sum_fit = sum(fitness)\n",
    "        selection_probs = [fitness[c]/sum_fit for c in range(len(population))]\n",
    "\n",
    "        return list(np.random.choice(population, int(N), p=selection_probs))\n",
    "\n",
    "    \n",
    "    # Roullette wheel selection\n",
    "    def select_param(self, population, fitness, hp : bool) -> list: \n",
    "#         population = self.population\n",
    "        sum_fit = sum(fitness)\n",
    "        selection_probs = [fitness[c]/sum_fit for c in range(len(fitness))]\n",
    "\n",
    "        if hp == False:\n",
    "            return np.random.choice(population, 2, p=selection_probs)\n",
    "\n",
    "        else:\n",
    "            p1 = np.random.choice(population, p=selection_probs)\n",
    "            hp_space = [c for c in range(len(population)) if list(p1.keys())[-1] in list(population[c].keys())]\n",
    "            hp_sum_fit = sum([fitness[c] for c in hp_space])\n",
    "            hp_selection_probs = [fitness[c]/hp_sum_fit for c in hp_space]\n",
    "            p2 = population[np.random.choice(hp_space, p=hp_selection_probs)]\n",
    "            return [p1, p2]\n",
    "        \n",
    "        \n",
    "    # cp : crossover probability ~ (0,1) -> 0.9\n",
    "    def crossover(self, population, fitness, num_offering : int, cp : float) -> dict:\n",
    "#         population = self.population\n",
    "        result = []\n",
    "        n = int(num_offering*cp)\n",
    "        hp_options = [True, False]\n",
    "        for _ in range(n):\n",
    "            hp_option = hp_options[np.random.randint(0, 2)]\n",
    "            child = {}\n",
    "            p1, p2 = self.select_param(population, fitness, hp=hp_option)\n",
    "            co_point = np.random.randint(low=0, high=len(p1))\n",
    "            for idx, key in enumerate(list(p2.keys())):\n",
    "                if idx < co_point:\n",
    "                    child[key] = p1[key]\n",
    "                else:\n",
    "                    child[key] = p2[key]\n",
    "            result.append(child)\n",
    "#         self.population = population.extend(result)\n",
    "        \n",
    "        return result\n",
    "    \n",
    "\n",
    "    # mp : crossover probability ~ (0,1) -> 0.03\n",
    "    def mutation(self, population, N, mp : float):\n",
    "#         population = self.population\n",
    "        \n",
    "        n = int(N*mp)\n",
    "\n",
    "        result = []\n",
    "        for _ in range(n):\n",
    "            child = {}\n",
    "            parent = population[np.random.choice(len(population))]\n",
    "            params = [list(parent[key].keys())+[key] if key in list(self.options['params'].keys()) \n",
    "                      else key for key in list(parent.keys())]\n",
    "            params.extend(params.pop())\n",
    "\n",
    "            ml_model = params[-1]\n",
    "            mut_param = params[np.random.randint(low=0, high=len(params)-2)]\n",
    "            if mut_param in list(self.options.keys()):\n",
    "                parent[mut_param] = self.rand_choice(self.options, mut_param)\n",
    "            else:\n",
    "                parent[ml_model][mut_param] = self.rand_choice(self.options['params'][ml_model], mut_param)\n",
    "            result.append(parent)\n",
    "\n",
    "        return result\n",
    "\n",
    "    \n",
    "    \n",
    "    def fitness(self, tot_score, failure_rate, tot_time):\n",
    "        highest_acc_pop = np.argmax(tot_score)\n",
    "\n",
    "        # fitness = (acc + (1-failure_rate) + time_cost + acc_decrease)/4\n",
    "        tot_fitness = [round((tot_score[i] + (1-failure_rate[i]) )/2, 4) for i in range(len(tot_score))]\n",
    "        \n",
    "        return tot_fitness\n",
    "    \n",
    "        \n",
    "    def indexbased_encoding(self, df, prefix):\n",
    "        #df = self.df\n",
    "        new_df = pd.DataFrame()\n",
    "        for column in df.columns:\n",
    "            if (column == 'Label') or (column == self.caseid) :\n",
    "                case_df = df.groupby(self.caseid, as_index = False).first()[column]\n",
    "                new_df = pd.concat([new_df, case_df], axis=1)\n",
    "            \n",
    "            elif ((column in self.feature_types) and  (column in self.num_event)):\n",
    "                col_name = [str(column)+str(i+1) for i in range(prefix)]\n",
    "                col_list = []\n",
    "                for case, group in df.groupby(self.caseid):\n",
    "                    group = group.sort_values(by='event_nr', ascending = True).reset_index(drop=True)\n",
    "                    col_list.append(group[column].tolist())\n",
    "                col_list = np.array(col_list)\n",
    "                event_df = pd.DataFrame(col_list, columns = col_name)    \n",
    "                new_df = pd.concat([new_df, event_df], axis=1)\n",
    "                \n",
    "                \n",
    "            elif (column == self.activity) or ((column in self.feature_types) and (column in self.string_event)) or ((column in self.feature_types) ):                \n",
    "                col_name = [str(column)+str(i+1) for i in range(prefix)]\n",
    "                col_list = []\n",
    "                for case, group in df.groupby(self.caseid):\n",
    "                    group = group.sort_values(by='event_nr', ascending = True).reset_index(drop=True)\n",
    "                    col_list.append(group[column].tolist())\n",
    "                col_list = np.array(col_list)\n",
    "                event_df = pd.DataFrame(col_list, columns = col_name)\n",
    "                for oh_col in event_df.columns:\n",
    "                    one_hot = pd.get_dummies(event_df[oh_col], prefix=oh_col, prefix_sep='_')\n",
    "                    event_df = event_df.drop(oh_col, axis=1)\n",
    "                    event_df = event_df.join(one_hot)\n",
    "                new_df = pd.concat([new_df, event_df], axis=1)\n",
    "        self.df = new_df\n",
    "        return new_df#self.one_hot_encoding(new_df)\n",
    " \n",
    "\n",
    "\n",
    "    def aggregated_encoding(self, df, prefix):\n",
    "        # df = self.df\n",
    "        new_df = pd.DataFrame()\n",
    "        for column in df.columns:\n",
    "            if (column == 'Label') or (column == self.caseid):\n",
    "                case_df = df.groupby(caseid, as_index = False).first()[column]\n",
    "                new_df = pd.concat([new_df, case_df], axis=1)\n",
    "                \n",
    "            elif ((column in self.feature_types) and (self.feature_types[column] == 'case')and (column in self.string_event)):\n",
    "                case_df = df.groupby(caseid, as_index = False).first()[column]\n",
    "                new_df = pd.concat([new_df,pd.get_dummies(case_df,prefix=column,prefix_sep='_') ], axis=1)\n",
    "                \n",
    "            \n",
    "            elif ((column in self.feature_types) and (self.feature_types[column] == 'case')and (column in self.num_event)):\n",
    "                case_df = df.groupby(caseid, as_index = False).first()[column]\n",
    "                new_df = pd.concat([new_df, case_df], axis=1)\n",
    "            \n",
    "            elif (column == self.activity) or ((column in self.feature_types) and (self.feature_types[column] == 'event') and (column in self.string_event)) :\n",
    "                col_name = [str(column)+str(i+1) for i in range(prefix)] #prefix\n",
    "                col_list = []\n",
    "\n",
    "                for case, group in df.groupby(self.caseid):\n",
    "                    group = group.sort_values(by='event_nr', ascending = True).reset_index(drop=True)\n",
    "                    col_list.append(group[column].tolist())\n",
    "                col_list = np.array(col_list)\n",
    "                str_event_df = pd.DataFrame(col_list, columns = col_name)\n",
    "\n",
    "\n",
    "\n",
    "                col_diff_1 = []\n",
    "                str_concat_df = pd.DataFrame()\n",
    "                for cd in range(prefix): #prefix\n",
    "                    col_diff_2 = str_event_df.iloc[:,cd].tolist()\n",
    "                    if (len(set(col_diff_1))+len(set(col_diff_2))) == len(set(col_diff_1)^set(col_diff_2)):\n",
    "                        str_concat_df = pd.concat([str_concat_df,pd.get_dummies(str_event_df.iloc[:,cd])],axis=1,ignore_index=False)\n",
    "                    else: #교집합 있는경우\n",
    "                        str_concat_df = pd.concat([str_concat_df,pd.get_dummies(str_event_df.iloc[:,cd])[list(set(col_diff_2)-set(col_diff_1))]],axis=1,ignore_index=False)\n",
    "                        str_concat_df[list(set(col_diff_1)&set(col_diff_2))] = str_concat_df[list(set(col_diff_1)&set(col_diff_2))]+pd.get_dummies(str_event_df.iloc[:,cd])[list(set(col_diff_2)&set(col_diff_1))]\n",
    "                    col_diff_1 = str_concat_df.columns.tolist()\n",
    "                str_concat_df.columns = [str(column)+str('_')+str(x) for x in str_concat_df.columns.tolist()]\n",
    "\n",
    "                new_df = pd.concat([new_df, str_concat_df], axis=1)\n",
    "\n",
    "\n",
    "            elif ((column in self.feature_types) and (self.feature_types[column] == 'event') and (column in self.num_event)) :  #min, max, mean, sum, std\n",
    "                col_name = [str(column)+str(i) for i in ['_min','_max','_mean','_sum','_std']] #prefix  \n",
    "                col_list = []\n",
    "\n",
    "                for case, group in df.groupby(self.caseid):\n",
    "                    group = group.sort_values(by='event_nr', ascending = True).reset_index(drop=True)\n",
    "                    col_list.append([np.min(group[column].tolist()),np.max(group[column].tolist()),np.mean(group[column].tolist()),np.sum(group[column].tolist()),np.std(group[column].tolist())])\n",
    "                col_list = np.array(col_list)\n",
    "                num_event_df = pd.DataFrame(col_list, columns = col_name)\n",
    "\n",
    "                new_df = pd.concat([new_df, num_event_df], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "                #np.transpose(A)\n",
    "        self.df = new_df\n",
    "        return new_df\n",
    "\n",
    "\n",
    "    \n",
    "    def encoding(self, df, key, prefix):\n",
    "        if key == \"index\":\n",
    "            return self.indexbased_encoding(df, prefix)\n",
    "        \n",
    "        elif key == \"aggregate\":\n",
    "            return self.aggregated_encoding(df, prefix)\n",
    "        \n",
    "    \n",
    "    def one_hot_encoding(self, df):\n",
    "        #df = self.df\n",
    "        for column in df.columns:\n",
    "            if not np.issubdtype(df[column], np.number):\n",
    "                one_hot = pd.get_dummies(df[column], prefix=column, prefix_sep='=')\n",
    "                #print(\"Encoded column:{} - Different keys: {}\".format(column, one_hot.shape[1]))\n",
    "                df = df.drop(column, axis=1)\n",
    "                df = df.join(one_hot)\n",
    "        #print(\"Categorical columns encoded\")\n",
    "        self.df = df\n",
    "        return df\n",
    "     \n",
    "    \n",
    "    def train_test_set_split(self, df, encoding):\n",
    "                \n",
    "        df_train, df_test = train_test_split(df, test_size=0.2, random_state=1, shuffle=False)\n",
    "#         print(f'Training samples: {len(df_train)} \\nTest samples: {len(df_test)}')\n",
    "        X_train = df_train.drop('Label', axis=1)\n",
    "        y_train = df_train['Label']\n",
    "        X_test = df_test.drop('Label', axis=1)\n",
    "        y_test = df_test['Label']\n",
    "        \n",
    "        if encoding == 'last_state':\n",
    "            ohe = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "            ohe.fit(X_train.values)\n",
    "            X_train = ohe.transform(X_train.values)\n",
    "            X_test = ohe.transform(X_test.values)\n",
    "\n",
    "            #X_train = self.one_hot_encoding(X_train)\n",
    "            #X_test = self.one_hot_encoding(X_test)\n",
    "        \n",
    "        else:\n",
    "            ratio = len(df_train[df_train['Label'] == 1]) / len(df_train[df_train['Label'] == 0])     \n",
    "#             print(f'Ratio of target in training set 0 : 1 = 1:{ratio:.4f}')\n",
    "\n",
    "            # For imbalanced data\n",
    "            if ratio < 0.33:\n",
    "                sm = SMOTE(random_state=0)\n",
    "                sm_X_train, sm_y_train = sm.fit_resample(X_train, y_train)\n",
    "                X_train = sm_X_train\n",
    "                y_train = sm_y_train\n",
    "                            \n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.X_test = X_test\n",
    "        self.y_test = y_test\n",
    "        \n",
    "        return X_train, y_train, X_test, y_test\n",
    "     \n",
    "    def model_fit(self):\n",
    "        #['Logistic Regression','Decision Tree','Random Forest','LightGBM','Xgboost','CatBoost']\n",
    "        models = {'Decision Tree' : DecisionTreeClassifier(), 'Random Forest' : RandomForestClassifier(), 'LightGBM' : LGBMClassifier(), 'Xgboost' : XGBClassifier()}\n",
    "        tot_score = []\n",
    "        for model in models:\n",
    "            score = []\n",
    "\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "\n",
    "            score.append(accuracy_score(self.y_test, model.predict(self.X_test)))\n",
    "            score.append(precision_score(self.y_test, model.predict(self.X_test)))\n",
    "            score.append(recall_score(self.y_test, model.predict(self.X_test)))\n",
    "            score.append(f1_score(self.y_test, model.predict(self.X_test)))\n",
    "            score.append(roc_auc_score(self.y_test, model.predict_proba(self.X_test)[:, 1]))\n",
    "\n",
    "            tot_score.append(score)\n",
    "\n",
    "        self.tot_score = tot_score\n",
    "\n",
    "        # plot score df\n",
    "        score_df = pd.DataFrame(tot_score, index = models, columns = ['Accuracy', 'Precision', 'Recall', 'F1 score', 'AUC'])\n",
    "        score_df.plot(kind=\"bar\",figsize=(9,8))\n",
    "        plt.xticks(rotation='horizontal')\n",
    "        plt.show()\n",
    "\n",
    "        self.score_df = score_df\n",
    "        return\n",
    "    \n",
    "    def decision_tree(self, hp, X_train, y_train, X_test, y_test):\n",
    "        model = DecisionTreeClassifier(max_depth = hp['max_depth'],\n",
    "                           min_samples_leaf= hp['min_samples_leaf'],\n",
    "                           criterion = hp['criterion'])\n",
    "        model.fit(X_train, y_train)\n",
    "        score  = round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4)\n",
    "        return score\n",
    "    \n",
    "    def random_forest(self, hp, X_train, y_train, X_test, y_test):\n",
    "        model = RandomForestClassifier(n_estimators=hp['n_estimators'], \n",
    "                           max_depth= hp[\"max_depth\"],\n",
    "                           max_features= hp[\"max_features\"], \n",
    "                           bootstrap= hp[\"bootstrap\"],\n",
    "                           criterion= hp[\"criterion\"])\n",
    "        model.fit(X_train, y_train)\n",
    "        score  = round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4)\n",
    "        return score\n",
    "    \n",
    "    def light_gbm(self, hp, X_train, y_train, X_test, y_test):\n",
    "        model = LGBMClassifier(max_depth= hp[\"max_depth\"],\n",
    "                           num_leaves= hp[\"num_leaves\"], \n",
    "                           min_child_samples= hp[\"min_child_samples\"])\n",
    "        model.fit(X_train, y_train)\n",
    "        score  = round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4)\n",
    "        return score\n",
    "    \n",
    "    def xgboost(self, hp, X_train, y_train, X_test, y_test):\n",
    "        model = XGBClassifier(max_depth = hp[\"max_depth\"],\n",
    "                           n_estimators = hp[\"n_estimators\"], \n",
    "                           learning_rate = hp[\"learning_rate\"])\n",
    "        model.fit(X_train, y_train)\n",
    "        score  = round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4)\n",
    "        return score\n",
    "        \n",
    "    def select_best_model(self):\n",
    "        score_df = self.score_df\n",
    "        arg_index = np.argmax(score_df['Accuracy'] + score_df['AUC'])\n",
    "    \n",
    "    \n",
    "    def main(self):\n",
    "        \n",
    "        populations = self.initial_populations(20)\n",
    "        tot_score = []\n",
    "        result_df, prefix_idx = whole_bucket(df)\n",
    "        for pop in populations:\n",
    "            df1 = drop_activity(df, pop['drop_act'])\n",
    "            bucket_list = bucketing(result_df, prefix_idx, pop['bucketing'])\n",
    "            for bucket in bucket_list:\n",
    "                score = []\n",
    "                df1 = result_df[bucket[0]:bucket[1]]\n",
    "                df1 = self.encoding(df1, pop['encoding'])\n",
    "                X_train, y_train, X_test, y_test = self.train_test_set_split(df1, pop['encoding'])\n",
    "                if 'Decision Tree' in pop:\n",
    "                    score.append(self.decision_tree(pop['Decision Tree'], X_train, y_train, X_test, y_test))\n",
    "                elif 'Random Forest' in pop:\n",
    "                    score.append(self.random_forest(pop['Random Forest'], X_train, y_train, X_test, y_test))\n",
    "                elif 'LightGBM' in pop:\n",
    "                    score.append(self.light_gbm(pop['LightGBM'], X_train, y_train, X_test, y_test))\n",
    "                else: \n",
    "                    score.append(self.xgboost(pop['Xgboost'], X_train, y_train, X_test, y_test))\n",
    "                tot_score.append(score)\n",
    "        new_df, prefix_idx = whole_bucket(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_dir+'dataset/'+test_log+'.csv', low_memory=False)\n",
    "df.dropna(axis=0,inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#selection rate\n",
    "sr = 0.1\n",
    "#crossover rate\n",
    "cr = 0.9\n",
    "#mutation rate\n",
    "mr = 0.01\n",
    "\n",
    "max_iter = 20\n",
    "\n",
    "\"\"\"\n",
    "GA : Genetic Algorithm\n",
    "RS : Random Search\n",
    "\"\"\"\n",
    "phase = 2 # drop_activity(GA) + encoding(GA) + bucketing(GA) + ML params(GA) + hyperparameter opt(RS)\n",
    "\n",
    "GA = Genetic_Algorithm(df, options, combi, caseid, activity, ts, label, other_features, string_event, num_event,phase)\n",
    "GA.feature_type()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "configuration_list = []\n",
    "fitness_function = []\n",
    "cnt = 0\n",
    "\n",
    "best_pop = []\n",
    "\n",
    "populations = GA.initial_populations(5)\n",
    "####\n",
    "fit_zip = []\n",
    "pop_zip = []\n",
    "re_zip = []\n",
    "sc_zip = []\n",
    "accu_zip = []\n",
    "auc_zip = []\n",
    "f1_zip = []\n",
    "y_test_balance_zip = []\n",
    "###\n",
    "\n",
    "generation_fitness = []\n",
    "generation_score = []\n",
    "generation_time = []\n",
    "generation_failure_rate = []\n",
    "for n_iter in range(max_iter):\n",
    "    new_population = []\n",
    "    tot_score = []\n",
    "    tot_time = []\n",
    "    failure_rate = []\n",
    "    for pop in tqdm(populations):\n",
    "        start_time = time.time()\n",
    "        new_population.append(pop)\n",
    "        if pop['drop_act'] == 2:\n",
    "            df_list = df_list1\n",
    "        elif pop['drop_act'] == 4:\n",
    "            df_list = df_list2\n",
    "        elif pop['drop_act'] == 6:\n",
    "            df_list = df_list3\n",
    "        else:\n",
    "            df_list = df_list4\n",
    "\n",
    "        if pop['encoding'] == 'last_state':\n",
    "            if pop['bucketing'] < 5:\n",
    "                pop['bucketing'] = 5\n",
    "            bound_list = prefix_bound(pop['bucketing'], drop_low=True)\n",
    "        else:\n",
    "            bound_list = prefix_bound(pop['bucketing'])\n",
    "\n",
    "        score = []\n",
    "        accu = []\n",
    "        auc = []\n",
    "        f1_ = []\n",
    "        y_test_balance = []\n",
    "\n",
    "        for bounds in bound_list:\n",
    "            lower, upper = bounds\n",
    "            merge_df = pd.DataFrame()\n",
    "            for idx in range(lower, upper):\n",
    "                prefix_df = df_list[idx-2]\n",
    "                prefix_df = GA.encoding(prefix_df, pop['encoding'], idx)\n",
    "                merge_df = pd.concat([merge_df, prefix_df], sort=False)\n",
    "            merge_df = merge_df.fillna(0)\n",
    "            X_train, y_train, X_test, y_test = GA.train_test_set_split(merge_df, pop['encoding'])\n",
    "            X_train.drop('Case ID', axis=1,inplace=True)\n",
    "            X_test.drop('Case ID', axis=1,inplace=True)\n",
    "            X_train.columns = [x for x in range(X_train.shape[1])]\n",
    "            X_test.columns = [x for x in range(X_test.shape[1])]\n",
    "            start = time.time()\n",
    "            y_test_balance.append(sum(y_test)/len(y_test))\n",
    "\n",
    "            if pop['models'] == 'Decision Tree':\n",
    "                model = DecisionTreeClassifier()\n",
    "                model.fit(X_train, y_train)\n",
    "                score.append(round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4))\n",
    "                accu.append(round(accuracy_score(y_test, model.predict(X_test)), 4))\n",
    "                auc.append(round((roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])), 4))\n",
    "                f1_.append(round((f1_score(y_test, model.predict(X_test))),4))\n",
    "\n",
    "            elif pop['models'] == 'Random Forest':\n",
    "                model = RandomForestClassifier()\n",
    "                model.fit(X_train, y_train)\n",
    "                score.append(round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4))\n",
    "                accu.append(round(accuracy_score(y_test, model.predict(X_test)), 4))\n",
    "                auc.append(round((roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])), 4))\n",
    "                f1_.append(round((f1_score(y_test, model.predict(X_test))),4))\n",
    "\n",
    "                \n",
    "            elif pop['models'] == 'LightGBM':\n",
    "                model = LGBMClassifier()\n",
    "                model.fit(X_train, y_train)\n",
    "                score.append(round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4))\n",
    "                accu.append(round(accuracy_score(y_test, model.predict(X_test)), 4))\n",
    "                auc.append(round((roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])), 4))\n",
    "                f1_.append(round((f1_score(y_test, model.predict(X_test))),4))                                \n",
    "                                                \n",
    "                                                \n",
    "            else: \n",
    "                model = XGBClassifier()\n",
    "                model.fit(X_train, y_train)\n",
    "                score.append(round((accuracy_score(y_test, model.predict(X_test))+roc_auc_score(y_test, model.predict_proba(X_test)[:, 1]))/2, 4))\n",
    "                accu.append(round(accuracy_score(y_test, model.predict(X_test)), 4))\n",
    "                auc.append(round((roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])), 4))\n",
    "                f1_.append(round((f1_score(y_test, model.predict(X_test))),4))                \n",
    "                                \n",
    "                                \n",
    "    \n",
    "        end_time = time.time()\n",
    "\n",
    "        elapsed_time = round(end_time-start_time,4)\n",
    "\n",
    "        tot_time.append(elapsed_time)\n",
    "        tot_score.append(round(sum(score)/len(score),4))\n",
    "\n",
    "        min_proba = 0.7\n",
    "        failure_rate.append(len([i for i in score if i < min_proba])/len(score))\n",
    "        \n",
    "        ####\n",
    "        re_zip.append(1-(len([i for i in score if i < min_proba])/len(score)))\n",
    "        sc_zip.append(round(sum(score)/len(score),4))\n",
    "        accu_zip.append(round(sum(auc)/len(auc),4))\n",
    "        auc_zip.append(round(sum(accu)/len(accu),4))\n",
    "        f1_zip.append(round(sum(f1_)/len(f1_),4))\n",
    "        y_test_balance_zip.append(round(sum(y_test_balance)/len(y_test_balance),4))\n",
    "\n",
    "        ####\n",
    "\n",
    "    fitness = GA.fitness(tot_score, failure_rate, tot_time)\n",
    "    fit_zip.extend(fitness)\n",
    "    best_pop.append(populations[np.argmax(fitness)])\n",
    "    pop_zip.extend(populations)\n",
    "\n",
    "    N = len(new_population)\n",
    "    pop1 = GA.select_population(new_population, fitness, N*sr)\n",
    "    pop2 = GA.crossover(new_population, fitness, N, cr)\n",
    "    pop3 = GA.mutation(new_population, N, mr)\n",
    "\n",
    "    populations = pop1 + pop2 + pop3\n",
    "\n",
    "    generation_fitness.append(round(sum(fitness)/len(fitness),4))\n",
    "    generation_time.append(sum(tot_time))\n",
    "    generation_score.append(round(sum(tot_score)/len(tot_score),4))\n",
    "    generation_failure_rate.append(round(sum(failure_rate)/len(failure_rate),4))\n",
    "\n",
    "    if cnt > 3:\n",
    "        break\n",
    "    \n",
    "    elif len(generation_fitness) > 1:\n",
    "        if abs(generation_fitness[-1]-generation_fitness[-2]) < 0.01:\n",
    "            break \n",
    "        elif (generation_fitness[-1]-generation_fitness[-2]) < 0:\n",
    "            cnt += 1    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "config = []\n",
    "for i,p in enumerate(pop_zip):\n",
    "    row_zip = list(p.values())[:-1]\n",
    "    row_zip.append(fit_zip[i])\n",
    "    row_zip.append(round(re_zip[i],4))\n",
    "    row_zip.append(sc_zip[i])\n",
    "    row_zip.append(accu_zip[i])\n",
    "    row_zip.append(auc_zip[i])\n",
    "    row_zip.append(f1_zip[i])\n",
    "    row_zip.append(y_test_balance_zip[i])\n",
    "    config.append(row_zip)\n",
    "    \n",
    "    \n",
    "\n",
    "df_config = pd.DataFrame(data=config,columns = (list(p.keys())[:-1]+['fit']+['re']+['sc']+['accu']+['auc']+['f1']+['y_ratio']))\n",
    "\n",
    "\n",
    "with open(file=file_dir+'GA_result/'+test_log+'_{}.pickle'.format(datetime.datetime.today().strftime(\"%d%H%M\")), mode='wb') as f:\n",
    "    pickle.dump(df_config, f)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "89ea80d57eb15db2b2c34f3c90a65f136145061d7e5ac43992953d1b221026f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
